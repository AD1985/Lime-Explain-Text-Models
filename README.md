# Model Interpretability

As the world is gearing towards model driven approach for most decision making, it is important to understand how a machine learning model is reaching to a decision. 

Most NLP models operate over high number of dimensions and so interpretability becomes even more important in such cases. 

This repository is an effort to explain use of LIME in explaiing a simple logistic alrogithm based text classification model. 
